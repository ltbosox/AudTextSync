<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Offline Transcriber — Vosk (WASM)</title>
<style>
:root {
  --bg:#111418; --panel:#161b21; --fg:#e8eef7; --muted:#9aa6b2; --line:#273044; --accent:#ffd666;
}
* { box-sizing:border-box }
html,body { height:100%; margin:0; background:var(--bg); color:var(--fg); font-family:sans-serif; }
button, input, select { font-size:1rem; }
.panel { background:var(--panel); padding:0.5rem; border-bottom:1px solid var(--line); }
.log { font-family:monospace; font-size:0.85rem; max-height:10rem; overflow:auto; border:1px solid var(--line); padding:0.25rem; background:#000; }
table { width:100%; border-collapse:collapse; }
th, td { border:1px solid var(--line); padding:0.25rem; text-align:left; }
audio { width:100%; }
</style>
</head>
<body>

<div class="panel">
  <label>Audio <input type="file" id="audioFile" accept="audio/*"></label>
  <label>Reference Text (optional) <input type="file" id="refFile" accept=".txt"></label>
  <button id="btnTranscribe">Transcribe</button>
</div>

<div class="panel">
  <label><input type="checkbox" id="adaptiveSync"> Adaptive sync (experimental)</label>
  <div id="modelStatus">Loading Vosk model…</div>
</div>

<div class="panel">
  <audio id="player" controls></audio>
</div>

<h3>Transcript</h3>
<div id="transcript">(no transcript yet)</div>

<h3>Per-word timestamps</h3>
<table id="wordTable">
<thead><tr><th>#</th><th>word</th><th>start</th><th>end</th><th>conf</th></tr></thead>
<tbody></tbody>
</table>

<h3>Log</h3>
<div class="log" id="log">(log starts here)</div>

<script type="module">
import Vosk from './vosk.js';

function addLog(level, msg, obj) {
  const logEl = document.getElementById('log');
  logEl.textContent += `\n[${new Date().toLocaleTimeString()}] ${level.toUpperCase()}: ${msg}${obj ? ' — ' + JSON.stringify(obj) : ''}`;
  logEl.scrollTop = logEl.scrollHeight;
}

const IS_MOBILE = /android|iphone|ipad|ipod/i.test(navigator.userAgent);
const BASE = new URL('.', location.href);
const MOBILE_MODEL_URL  = new URL('models/en-us-mobile.tar.gz', BASE).href;
const DESKTOP_MODEL_URL = new URL('models/en-us-desktop.zip', BASE).href;
const MODEL_URL = IS_MOBILE ? MOBILE_MODEL_URL : DESKTOP_MODEL_URL;

addLog('info','Detected platform', { mobile: IS_MOBILE });
addLog('info','Model URL chosen', { url: MODEL_URL });

let model;
try {
  addLog('info','Loading Vosk model…', IS_MOBILE ? '(mobile)' : '(desktop)');
  model = await Vosk.createModel(MODEL_URL);
  addLog('info','Model loaded successfully');
  document.getElementById('modelStatus').textContent = 'Model loaded';
} catch (e) {
  addLog('error','Model failed to load', e);
  document.getElementById('modelStatus').textContent = 'Model load failed';
}

document.getElementById('btnTranscribe').addEventListener('click', async () => {
  const audioFile = document.getElementById('audioFile').files[0];
  if (!audioFile) return alert('Please choose an audio file first.');
  document.getElementById('player').src = URL.createObjectURL(audioFile);
  
  const recognizer = new model.Recognizer({ sampleRate: 16000 });
  const arrayBuffer = await audioFile.arrayBuffer();
  const audioCtx = new AudioContext({ sampleRate: 16000 });
  const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
  const pcm = audioBuffer.getChannelData(0);

  recognizer.acceptWaveform(pcm);
  const result = recognizer.finalResult();
  displayTranscript(result);
});

function displayTranscript(result) {
  const transcriptDiv = document.getElementById('transcript');
  transcriptDiv.textContent = result.text || '(no text)';
  const tbody = document.querySelector('#wordTable tbody');
  tbody.innerHTML = '';
  (result.result || []).forEach((w,i) => {
    const tr = document.createElement('tr');
    tr.innerHTML = `<td>${i+1}</td><td>${w.word}</td><td>${w.start.toFixed(2)}</td><td>${w.end.toFixed(2)}</td><td>${w.conf.toFixed(2)}</td>`;
    tbody.appendChild(tr);
  });
}
</script>
</body>
</html>
